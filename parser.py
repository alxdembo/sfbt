import json
import os

import networkx as nx
import yaml
from dbt.graph import GraphQueue
from jsonschema.validators import validate

ROOT_DIR = os.path.abspath(os.getcwd())

CONFIG_YAML = ROOT_DIR + '/config.yml'
TEMPLATE_YAML = ROOT_DIR + '/template.yml'
TARGET_MANIFEST_JSON = ROOT_DIR + '/target/manifest.json'
COMPILED_PATH = ROOT_DIR + '/target/compiled/'
GRAPH_GPICKLE = ROOT_DIR + "/target/graph.gpickle"
statemachine_folder = ".aws_autogenerated/statemachine"


# todo feed parameters into function


def parse_step(graph, function_arn):
    result = {
        'Comment': 'Autogenerated',
        'StartAt': 'Parallel-0',
        'States': {
            'Parallel-' + str(n): {
                'Type': 'Parallel',
                'Next': 'Parallel-' + str(n + 1),
                'Branches': [
                    {
                        'StartAt': i,
                        'States': {
                            'Type': 'Task',
                            'Resource': function_arn,
                            'Parameters': {},
                            'End': True
                        }
                    } for i in m
                ]
            } for n, m in enumerate(graph)
        },
    }

    last_item = list(result['States'])[-1]

    del result['States'][last_item]['Next']
    result['States'][last_item]['End'] = True

    return result


def write_sam_template(run_config):
    sam_template = {
        "AWSTemplateFormatVersion": "2010-09-09",
        "Transform": "AWS::Serverless-2016-10-31",
        "Description": "Autogenerated",
        "Resources": {
            f'{p_name}_{k}_orchestrator': {
                "Type": "AWS::Serverless::StateMachine",
                "Properties": {
                    "Name": f'{p_name}_{k}_orchestrator',
                    'DefinitionUri': vals['definition_uri'],
                    'Policies': [{
                        'LambdaInvokePolicy': {
                            'FunctionName': vals['function_arn'].split(":function:")[1]
                        }
                    }]
                }
            } for k, pipeline in run_config.items() for p_name, vals in pipeline.items() if 'definition_uri' in vals}
    }

    with open(TEMPLATE_YAML, 'w') as f:
        f.write(yaml.dump(sam_template))


def yaml_load_validate(filename):
    with open(filename) as f:
        loaded = yaml.load(f, Loader=yaml.FullLoader)

    with open('./schemas' + filename) as schema:
        validator = yaml.load(schema, Loader=yaml.FullLoader)

    validate(loaded, validator)

    return loaded


def parse():
    run_config = yaml_load_validate(CONFIG_YAML)

    with open(TARGET_MANIFEST_JSON) as f:
        manifest = json.loads(f.read())

    os.makedirs(statemachine_folder, exist_ok=True)

    compiled_models = []
    for (dirpath, dirnames, filenames) in os.walk(COMPILED_PATH):
        compiled_models.extend(filenames)

    for resource_type, pipeline in run_config.items():
        for pipeline_name, v in pipeline.items():
            graph = nx.read_gpickle(GRAPH_GPICKLE)
            node_list = list(graph.nodes)

            for node_name in node_list:
                node = graph.nodes[node_name]
                if node['resource_type'] != resource_type or os.path.basename(node['path']) not in compiled_models:
                    graph.remove_node(node_name)

            if not list(graph):
                continue

            graph_sorted = list(GraphQueue._grouped_topological_sort(graph))

            run_config[resource_type][pipeline_name][
                'definition_uri'] = f'./{statemachine_folder}/{pipeline_name}_{resource_type}.asl.yaml'
            models = parse_step(graph_sorted, v['function_arn'])

            with open(run_config[resource_type][pipeline_name]['definition_uri'], 'w') as f:
                f.write(yaml.dump(models))

    write_sam_template(run_config)


if __name__ == '__main__':
    parse()
